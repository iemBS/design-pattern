Abbreviations
-YoY = Year over Year = Compare number on a date to the number on the same date a year ago 
-MoM = Month over Month = Compare number on a date to the number on the same date a month ago
-WoW = Week over Week = Compare number on a day to the number on the same day a week ago

Other
-PULL_FREQUENCY = An attribute that is needed for measures where measures can change from moment to moment and changing the pull frequency can cause large changes in the data. 

**TASK MEASURES**

Contributing Non-Measure (an attribute):
<>TASK_ID = Uniquely identifies the task 
<>PROCESS_RUN_ID = Uniquely identifies a run of a group of tasks
<>TASK_RUN_START_TIME = Start time of a specific run of a task
<>TASK_RUN_END_TIME = End time of a specific run of a task
<>TASK_RUN_DURATION_TIME_UNIT = Time unit to use for task run duration
<>TASK_RUN_ERROR = Error that occurred for a specific run of a task
<>TASK_RUN_STATUS = Has values of RUNNING, FAILED, SUCCEEDED. 
<>TASK_STATUS = Indicates if task is able to run
<>PROCESS_TASK_ORDER = Provides a number for a task to indicate the excution order of the tasks within the process
<>TASK_RUN_DURATION_LIMIT = Set in config per task. In same time units as TASK_RUN_DURATION.
<>TASK_RAM_USAGE_LIMIT = Set in config. Per task if possible.
<>TASK_NET_USAGE_LIMIT = Set in config. Per task if possible.
<>TASK_DSK_USAGE_LIMIT = Set in config. Per task if possible.
<>TASK_CPU_USAGE_LIMIT = Set in config. Per task if possible.
<>TASK_RUN_START_TIME_MAX_LIMIT = Set in config per task. Will be compared to TASK_RUN_END_TIME_MAX to see if run on schedule. This is part of a dynamic limit, instead of a static limit. 

Measure Hierarchy:
<>TASK_RUN_RAM_USAGE
<>TASK_RUN_CPU_USAGE
<>TASK_RUN_DSK_USAGE
<>TASK_RUN_RECORD_COUNT
<>TASK_RUN_DATA_VOLUME_MB
<>TASK_RUN_END_TIME_MAX = MAX(TASK_RUN_END_TIME) GROUP BY TASK_ID = See when the last refresh was completed for a task
<><>TASK_RUN_START_TIME_MIN = Expectation of a scheduled run. Translated to be a min time. This would also be dynamic to check against TASK_RUN_START_TIME on a schedule.
<><>TASK_DISTINCT_COUNT = DISTINCT_COUNT(TASK_ID) = Distinct count of tasks regardless of task to process relation
<><>TASK_PROCESS_DISTINCT_COUNT = DISTINCT_COUNT(PROCESS_RUN_ID) GROUP BY TASK_ID = # of processes using specific task
<><>PROCESS_RUN_TASK_COUNT = COUNT(PROCESS_RUN_ID) GROUP BY PROCESS_RUN_ID = # of tasks executed in specific process run
<><>TASK_RUN_COUNT = COUNT(TASK_ID) GROUP BY TASK_ID = Run count of task regardless of how many processes use the task
<><>PROCESS_TASK_RUN_COUNT = COUNT(TASK_ID) GROUP BY TASK_ID,PROCESS_RUN_ID = Run count for a task for process
<><>TASK_RUN_ERROR_COUNT = COUNT(PROCESS_RUN_ID) WHERE TASK_RUN_ERROR EXISTS
<><>PROCESS_TASK_RUN_DURATION = TASK_RUN_END_TIME - TASK_RUN_START_TIME GROUP BY PROCESS_RUN_ID
<><>PROCESS_TASK_RUN_DURATION_MIN = MIN(PROCESS_TASK_RUN_DURATION)
<><>PROCESS_TASK_RUN_DURATION_MAX = MAX(PROCESS_TASK_RUN_DURATION)
<><><>PROCESS_RUN_DURATION = SUM(PROCESS_TASK_RUN_DURATION) GROUP BY PROCESS_RUN_ID
*<><>TASK_RUN_COMPLETION_STATUS = where TASK_RUN_END_TIME not exist or TASK_RUN_DURATION is 0
<><>TASK_RUN_OVERLAP_STATUS = where TASK_1_RUN_END_TIME > TASK_2_RUN_START_TIME WHERE (PROCESS_TASK_1_ORDER = PROCESS_TASK_2_ORDER-1) GROUP BY PROCESS_RUN_ID
<><>TASK_RUN_DURATION_LIMIT_EXCEEDED_STATUS = where PROCESS_TASK_RUN_DURATION > TASK_RUN_DURATION_LIMIT
<><>AVG_TASK_RECORD_COUNT = SUM(TASK_RUN_RECORD_COUNT) / TASK_RUN_COUNT = Avg task count regardless of task to process relation
<><>AVG_TASK_DATA_VOLUME_MB = SUM(TASK_RUN_DATA_VOLUME_MB) / TASK_RUN_COUNT
<><><>AVG_RAM_USAGE = SUM(TASK_RUN_RAM_USAGE) / TASK_RUN_COUNT
<><><>TASK_COMPLETE_COUNT = COUNT(PROCESS_RUN_ID where TASK_RUN_COMPLETION_STATUS is 1)
<><><>AVG_TASK_RUN_DURATION = SUM(TASK_RUN_DURATION) / TASK_COUNT = Average task run duration. Valuable to know what to expect when testing and monitoring tasks.
<><><>TASK_RECORD_COUNT_HIGH = where TASK_RECORD_COUNT > AVG_TASK_RECORD_COUNT
<><><>TASK_DATA_VOLUME_MB_HIGH = = where TASK_DATA_VOLUME_MB > AVG_TASK_DATA_VOLUME_MB
<><><>TASK_ERROR_PCT = TASK_ERROR_COUNT / TASK_COUNT
<><><><>TASK_COMPLETION_PCT = TASK_COMPLETE_COUNT / TASK_COUNT
<><><><>TASK_SLOW = where TASK_RUN_DURATION > AVG_TASK_RUN_DURATION
<><><><>TASK_FAST = where TASK_RUN_DURATION < AVG_TASK_RUN_DURATION
<><><><><>AVG_TASK_COMPLETION_PCT = SUM(TASK_COMPLETION_PCT) / # of times the TASK_COMPLETION_PCT was recorded 

**SOFTWARE CODE MEASURES**

Measure Hierarchy:
<>METHOD_COUNT
<>CLASS_COUNT
<>PROPERTY_COUNT
<>VARIABLE_COUNT 
<>METHOD_LINE_COUNT
<>METHOD_CALL_COUNT = # of times a method was called from all other methods
<><>AVG_METHOD_LINE_COUNT
<>xxx:fill in

**HARDWARE MEASURES**

Contributing Non-Measure (an attribute):
<>RAM_USAGE
<>CPU_USAGE
<>DSK_USAGE
<>NET_USAGE
<>PULL_FREQUENCY

Measure Hierarchy:
<>RAM_USAGE_AVG = AVG(RAM_USAGE)
<>CPU_USAGE_AVG = AVG(CPU_USAGE)
<>DSK_USAGE_AVG = AVG(DSK_USAGE)
<>NET_USAGE_AVG = AVG(NET_USAGE)
xxx:fill in

**DATA VOLUME MEASURES**
Measure Hierarchy:
<># of records searched
<># of records returned
<>MBs of data searched
<>MBs of data returned 
<>xxx:fill in 


**DATA CHANGE MEASURES**
Contributing Non-Measure (an attribute):
<>DATA_CHANGE_LEVEL = change at Field or Record level
<>DATA_CHANGE_TIME = time the data was changed 

Measure Hierarchy:
<>RECORD_INSERT_COUNT
<>RECORD_UPDATE_COUNT
<>RECORD_DELETE_COUNT
xxx:fill in

**DATA QUALITY MEASURES**
Measure Hierarchy:
<>FIELD_DISTINCT_VALUE_COUNT
<>FIELD_VALUE_COUNT
<><>FIELD_PERCENT_DISTINCT = (FIELD_DISTINCT_VALUE_COUNT/FIELD_VALUE_COUNT) x 100
xxx:fill in

**DATA USER MEASURES**
Contributing Non-Measure (an attribute):
<>DB = A single database
<>DB_ROLE = Role in DB
<>DB_USER = User in DB
<>DB_ROLE_USED = DB Role used to run a query
<>DB_USER_USED = DB User used to run a query
<>QUERY_RUN = Run of a query 
<>PULL_FREQUENCY

Measure Hierarchy:
<>DB_ROLE_COUNT = COUNT(DB_ROLE) = Count of roles in DB
<>DB_USER_COUNT = COUNT(DB_USER) = Count of users in DB
<>DB_ROLE_USED_COUNT = COUNT(DB_ROLE_USED) = Count of roles used in DB
<>DB_QUERY_RUN_COUNT = COUNT(QUERY_RUN) GROUP BY DB
<><>DB_ROLE_QUERY_RUN_COUNT = COUNT(QUERY_RUN) GROUP BY DB_ROLE
<><><>DB_ROLE_QUERY_RUN_COUNT_MAX = MAX(COUNT(QUERY_RUN) GROUP BY DB_ROLE) GROUP BY DB_ROLE = Max count of queries run by a single role
<><><>DB_ROLE_QUERY_RUN_COUNT_AVG = AVG(COUNT(QUERY_RUN) GROUP BY DB_ROLE) GROUP BY DB_ROLE = Average count of queries run by a single role
<><>DB_USER_QUERY_RUN_COUNT = COUNT(QUERY_RUN) GROUP BY DB_USER
<><><>DB_USER_QUERY_RUN_COUNT_MAX = MAX(COUNT(QUERY_RUN) GROUP BY DB_USER) GROUP BY DB_USER = Max count of queries run by a single user
<><><>DB_USER_QUERY_RUN_COUNT_AVG = AVG(COUNT(QUERY_RUN) GROUP BY DB_USER) GROUP BY DB_USER = Average count of queries run by a single user

**LOG MEASURES**
Contributing Non-Measure (an attribute):
<>INGEST_TIME
<>LOG_ENTRY_CREATE_TIME

Measure Hierarchy:
<>INGEST_DURATION = INGEST_TIME - LOG_ENTRY_CREATE_TIME
<><>AVG_INGEST_DURATION = AVG(INGEST_DURATION)
<><>MIN_INGEST_DURATION = MIN(INGEST_DURATION)
<><>MAX_INGEST_DURATION = MAX(INGEST_DURATION)


Define Measure
Main Success Scenario:
  1. "Define Reporting Goal"
  2. "Define Metric Role in Reporting Goal"
  3. "Define Metric Audience"
  4. "Define Min Data Quality for Metric"
  5. "Define Metric Business Logic"
  6. "Define Metric Technical Logic" 
  7. "Define Supporting Detail for Metric"
  
  
Define Reporting Goal
Main Success Scenario:
  1. "Understand Report Refresh Periods"
  2. "Understand Metric Comparison Periods"
  x. xxx:fill in
  
  
Understand Report Refresh Periods
Note:
  -Common reporting refreshes:
    -daily
    -weekly
    -monthly
    -quarterly
    -every 6 months
    -annually
Main Success Scenario:
  1. xxx:fill in
  
  
Understand Metric Comparison Periods
Note:
  -Common comparison periods:
    -today to yesterday
    -this week to last week 
    -this month to previous month
    -this quarter to previous quarter
    -this 6 months to the previous 6 months
    -this year to last year
Main Success Scenario:
  1. Note periods to compare
  2. Note fixed periods
  3. End
Alternatives:
  2a. Note moving periods
    2a1. xxx:fill in
    2a2. Go to step 3
  
  
Define Metric Role in Reporting Goal
Main Success Scenario:
  1. xxx:fill in
  
  
Define Metric Audience
Main Success Scenario:
  1. What motivates the audience to use the metric?
  2. Does the audiance understand how to make the metric value better?
  
  
Define Min Data Quality for Metric
Main Success Scenario:
  1. xxx:fill in
  
  
Define Metric Business Logic
Main Success Scenario:
  1. "Define Metric Time Attribute"
  2. xxx:fill in
  

Define Metric Technical Logic
Main Success Scenario:
  1. xxx:fill in

  
Define Metric Time Attribute
Main Success Scenario:
  1. xxx:fill in
  
  
Define Supporting Detail for Metric
Main Success Scenario:
  1. xxx:fill in
  

Define Finance Metric
Note:
  -guidance @ 
    -https://www.investopedia.com/financial-edge/0910/6-basic-financial-ratios-and-what-they-tell-you.aspx
Main Success Scenario:
  1. xxx:fill in
  
  
Define Index 
Note
 -Most commonly used simple index numbers are price, quantity, and value.
 -An index can incorporate several factors into a single metric 
Main Success Scenario:
  1. xxx:fill in
  
  
Categorize Measure
Main Success Scenario:
  1. xxx:fill in
  

**Relate Measure**
-RAM_USAGE, CPU_USAGE, DSK_USAGE, and NET_USAGE = searching for haredware resource impact on other hardware resources
--Se impact of hardware resource attributes on each other
-TASK_RUN_START_TIME, TASK_RUN_DURATION
--See impact of task run start time on the duration of a task
-TASK_RUN_START_TIME, TASK_RUN_END_TIME, RAM_USAGE, CPU_USAGE, DSK_USAGE, and NET_USAGE = See hardware resource use while a task runs. Need to define hardware measure update frequency. 
--See impact of hardware resource % usage of max and task run start time on task duration

  
  
**Chart attribute**
<># of variables
<>min & max value per variable 
<><>set vs dynamic
<>legend
<>variable label
<>variable unit
<>title
<>dynamic vs scheduled refresh vs on-demand refresh
<>if using time
  -value display period
  -period = granularity of time data values, aggregation can aggregate a greater number of values for smaller time periods to fewer values for larger time periods

**Chart quality**
<>xxx

  
**Chart type**
-chart references
--https://support.microsoft.com/en-us/office/available-chart-types-in-office-a6187218-807e-4103-9e0a-27cdb19afb90
--https://support.google.com/docs/answer/190718?hl=en#zippy=
--https://flowingdata.com/chart-types/
--https://en.wikipedia.org/wiki/Chart
--https://chartio.com/learn/charts/essential-chart-types-for-data-visualization/
-https://blog.hubspot.com/marketing/types-of-graphs-for-data-visualization
<>Line 
<>Bar 
<><>Clustered 
<><><>3-D
<><><>2-D
<><>Histogram
<><><>ex: Test Scores @ https://support.google.com/docs/answer/9146867#zippy=%2Ctest-scores
<><>Stacked 
<><><>3-D
<><><>2-D
<><>Waterfall
<>Geo
<><>Geo with Markers
<><><>ex: Internet Usage per Country @ https://support.google.com/docs/answer/9143071#zippy=%2Cgeo-chart-with-markers
<>Pie
<><><>3-D
<><><>2-D
<>Donut
<>Area
<>Funnel
<>Column
<><>Waterfall
<>Stock
<>Radar
<><>req: Has 3 or more variables
<>Box and Whisker/Candlestick
<>Sunburst
<>Surface
<>Map
<><>Density 
<><>Tree 
<><><>req: Have label hierarchy, bottom level labels have associated values that can be aggregated to higher levels in label hierarchy, all bottom level values have values
<><><>ex: College Major distribution @ https://support.google.com/docs/answer/9146947#zippy=%2Clunch-menu%2Ccollege-majors
<><><>ex: Lunch Menu Cost @ https://support.google.com/docs/answer/9146947#zippy=%2Clunch-menu
<>Scatter Plot
<>Gantt 
<><>ex: timeline @ xxx:fill in 
<>Bubble
<><>req: Has 3 variables
<>Gauge

*Goal per Chart Type**
<>xxx

**Pros & Cons per Chart Type**
<>xxx

**Chart combination**
<>overlap
<><>xxx
<>next to
<><>xxx
  
**Map Measure to Chart**
<>xxx

**Evolution of Task Measure (handy for breaking up into releases)
<>xxx:fill in 
<>If a task is run more than once in a process a PROCESS_RUN_ID will not help. Use a TASK_RUN_ID to represent a specific run of a task for PROCESS_RUN_ID and to associate to the TASK_RUN_START_TIME and TASK_RUN_END_TIME for the task run. 
<>Associate other types of measures to the tasks
<><>Associate Hardware Resource Usage measures
<><><>DSK_USAGE
<><><>RAM_USAGE
<><><>NET_USAGE
<><><>CPU_USAGE
<><>Associate Task Execution Measures
<><><>ITEM_COUNT
<><><>TABLE_ROW_COUNT
<><><>TABLE_INSERT_ROW_COUNT
<><><>TABLE_UPDATE_ROW_COUNT
xxx:fill in


**Evolution of Task Measure via charts (handy for breaking up into releases)
-xxx:fill in

 
