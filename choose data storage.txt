Choose Data Storage
Note:
  - [xxx: need to sharpen this]
Main Success Scenario:
  1. Understand Data to choose from
  2. Choose data to go into the new data storage
  3. "Define Audiences" use case
  4. "Define Data Attributes" use case
  5. "Define Host Attributes" use case
  6. "conn" use case
  7. "Purpose" use case
  8. "Stages" use case
  9. "query" use case
  10. "log" use case


Define Audiences
Main Success Scenario:
  1. Who wants to interact w data and why
  2. mngmt OKs user add to Audience
  3. users put into audiences
  4. "Define Security" use case


Define Security
Main Success Scenario
  1. Assign permissions to each audience


Define Data Attributes
Main Success Scenario:
  1. "Define Data Size" use case
  2. "chg time" use case
  3. "chg freq" use case
  4. "in time" use case
  5. "in freq" use case
  6. "out time" use case
  7. "out freq" use case


Define Host attributes
Preconditions:
  - Have a list of potential data storage hosts
Main Success Scenario:
  1. "compression" use case
  2. "redundancy" use case
  3. "up time" use case
  4. "data structure" use case
  5. "Choose Data Storage Type" use case
  6. "env" use case
  7. "cost" use case
  8. Host and Host connection security
  9. CPU usage


Define Data Size
Preconditions: 
  - Have a list of potential data storage hosts
Main Success Scenario:
  1. Get Current data size
  2. Est data growth
  3. Get min data size host handles
  4. Get max data size host handles
  
  
Choose Data Storage Type
Preconditions:
  - Use Data Storage Type Decision Tree
  - Use DB Type Decision Tree
Main Success Scenario:
  1. Find most sensible storage type for the data's purpose and usage
  2. If using a DB, find the most sensible DB type for the data's purpose and usage


chg freq
  -chg freq in the past
  -est chg freq in future
chg time
  -max time it took to change data in past
  -est max time it will take to chg data in future
in time
  -max time it took to insert data in past
  -est max time it will take to insert data in future
in freq
  -insert freq in the past
  -est insert freq in future
  -insert static vs live/streaming
out time
  -max time it took to extract data in past
  -est max time it will take to extract data in future
out freq
  -extract freq in the past
  -est extract freq in future
compression
  -% of compression achieved within data storage
  -is data compressed during insert and uncompressed during extract
redundancy
  -is redundancy needed
     -does host provide redundancy
        -how many redundanct copies exist
        -how old are copies
        -where to copies exist (same physical disk, same server, same server farm, same building, same country)
up time
  -when we need storage to be up
  -host reliability
conn 
  -rate
     -min conn rate from each geo that will insert, update, & extract data
     -max conn rate from each geo that will insert, update, & extract data
  -simulataneous users
     -max # simulataneous users host allows
     -max # simulataneous users reached
     -how often "max # simulataneous users host allows" is reached
     -max # simulataneous users reached per geo
query
  -quality of queries run against data storage (lower quality leads to lower performance & higher cost)
  -language intuitive for devs to use
  -canned, optimized queries available for users and devs
  -max wait time before query starts executing
  -avg wait time before query starts executing
  -calc done on the fly by users via prepped calcs before data is accessible to users
purpose
  -Purposes define if data needs to be broken up or matured into more than one data storage
data structure
  -data using most sensible structure for it's purpose and usage
env
  -Prod env exists 
     -only queries already optimized, tested, and have clear purpose in Prep env run here
  -Prep env exists
     -devs optimize, test, and define purpose for queries
  -env based on geo
stages
  -stages that data needs to go through
  -data moved during stage chg or are stages applied to non-moving data
cost
  -cost to store data in in host
  -cost to query (update, insert, extract) host
  -cost of redundancy
  -cost to backup
  -cost to monitor
  -cost up conn rate upgrade
log
  -can log query runs
  -log used to make better data storage choices


DB Types
  Note: Guidance from 
          https://en.wikipedia.org/wiki/NoSQL
          https://en.wikipedia.org/wiki/Wide_column_store
          https://en.wikipedia.org/wiki/Triplestore
          https://en.wikipedia.org/wiki/Network_model
          https://en.wikipedia.org/wiki/Tuple_space
  - SQL
      Relational
  - NoSQL
    - Key-Value
      - Key-Value Cache
      - Key-Value Store
          def: 
            - use associative array / map / dictionary
            - simple data model
      - Key-Value Store (eventually-consistent)
      - Key-Value Store (Ordered)
    - Data-Structures Server
        ex: Redis
    - Tuple Store
        ex: Apache > River
    - Object
        def: 
          - data stored as objects like in object oriented programming
    - Object-Relational
        def: 
          - hybrid of relational and object DB approaches
    - Document Store
        def: 
          - use XML, YAML, JSON, or BSON encoding in doc
          - each doc has unique key
          - each doc can have it's own unique structure
        ex: MongoDB, Couchbase, CouchDB, Elasticsearch, DocumentDB
    - Wide Column Store
        def: 
          - 2-D key-value store
          - Unlike a relational DB, column names and formats can vary from row to row in same table
        ex: AWS > DynamoDB, GCP > BigTable, Apache > Cassandra, Apache > HBase
    - Wide Column Store (w column families) / Column Family DB
        def: 
          - Has column families that are stored together
    - Native Multi-Model DB
        ex: MS > Cosmos DB
    - Graph
        def: 
          - relationships also have properties
          - connection heavy
        ex: Neo4j, AWS > Neptune
        
      - Triplestore / RDF Store
          def: 
            - Purpose-built DB for storage & retrieval of triples
            - Triple = subject-predicate-object
      - Quadstore / Named Graph
          def: 
            - Purpose-built DB for storage & retrieval of quads
            - Quad = name-subject-predicate-object
      - Network
          def: 
            - Each record having one parent record and many children
            - Hierarchical database model structures data as a tree of records
    - Column
        def: 
          - Each column is stored separately on disk
          - has column families
          - column families stored seperately
        ex: Cassandra, Hbase
        
        
DB Features
   guidance from
     https://en.wikipedia.org/wiki/Database#Transactions_and_concurrency
     https://www.mssqltips.com/sqlservertip/5980/sql-and-nosql-database-features-and-differences/
- transaction
  - [xxx: need to fill in]
- architecture
  - memory structure
  - process structure
  - storage structure
- move data
  - [xxx: need to fill in]
- concurrency
  - [xxx: need to fill in]
- migrate
  - [xxx: need to fill in]
- log
  - [xxx: need to fill in]
- software enhancement
  - update
  - add-on
    - from DB software maker
    - from 3rd party
- backup 
  - full or incremental
  - auto or manual
  - mngmt
- restore
  - [xxx: need to fill in]
- schema
  - NoSQL is schemaless, which contributes to fast writes
- read/write perf mngmt (RDB read & write optimized, NoSQL optimized for write)
  - query tune
  - db tune
    - normalization
    - indices
      - used by RDG & NoSQL to make reads faster
    - partitioning
  - server software tune
  - server hardware tune
- field
- record
- collection of records
- security
  - [xxx: need to fill in]
- computer language
  - supports common DB computer languages
    - ANSI SQL is a widely accepted language for DBs
  - acceptance in dev community
  - ease of use
- ACID (atomicity, consistency, isolation, durability) support 
  - Atomicity: 
    - Every transaction in a SQL DB is a unit of work
    - Trancompletes completes in its entirety or it does not
  - Consistency: 
    - Ensures a DB always remains in a valid state following a transaction
    - Valid state means the data will not breach any primary key, foreign key, constraint, trigger, cascade or other business rules when a transaction completes
  - Isolation: 
    - A relational DB can run multiple transactions on the same piece of data from diff connections      
    - Dictates that when these concurrent transactions finish, the data will be in such a state as if the transactions were played sequentially. 
    - Determines the transaction isolation level run time setting in database engine
  - Durability: 
    - Makes sure data is permanently persisted when a transaction completes 
    - Even if there is a power or hardware failure before the actual data is written to disk, the DB engine will be able to recover the transaction and bring the DB to a consistent state. 
    - Basis of how the SQL Server transaction log works
- CAP theorem support for NoSQL DBs
    - Consistency: 
      - After a write operation, all copies of a data element will be exactly the same in all nodes
      - Similarly, with a read query, all nodes responding to the request will have the same data
    - Availability: 
      - Req number of nodes in the cluster needs to be present during data read or write operation    
      - If there is no response from the required number of nodes ...
        - Transaction fails
           or
        - Read request returns an error
    - Partition Tolerance: 
      - System remains online and functioning even if one or more nodes are unavailable
      - Data element is sufficiently replicated between multiple nodes so any outage (network or hardware) does not affect the system
- BASE principle
    - When a NoSQL DB gives up consistency for availability & partition tolerance
    - Basically Available: It means the system is available even if some parts of it are unreachable.
    - Soft state: It means parts of the distributed database can contain different versions of the same data. This can happen when certain nodes have not synched up with the latest copy of the data.
- join support
    - Eventual Consistency: 
      - At some point in time, the inconsistent nodes will catch up with the latest copy of data and the system will become "eventually consistent".  
      - "Eventually consistent" is not guarantee to happen
- one query or multiple queries for extract
- caching
  - storing copy of query results to reduce queries running against DB
- normalized vs non-normalized
    - Normalization streamlines storage and eliminates duplication. Some reads will need joins. 
    - Denormalization increases data size by allowing duplication. Reads less likely to need joins.
- nesting data
- scalability
  - vertical: 
      - Add more CPU and RAM resources
      - Seperate read & write workload using load balancing, clustering, or replication
  - horizontal
      - Server is a node and DB cluster made up of multiple nodes
      - Each node in DB cluster work as reader & writeer and data distributed to all nodes
      - New nodes easily added to cluster and existing data auto-redistributes among nodes 
      - Usually used by NoSQL DB 
- task scheduling
- min storage size
- max storage size
- relationship
  - define relationships that can be joined on
- API
- connectors for other software or computer languages
- platform availability
  - Server & Client software available for mulitple OSes

